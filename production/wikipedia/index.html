<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">

  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
  <meta name="description" content="Charlie Marsh is a programmer and student at Princeton University with major interests in functional programming and machine learning.">
  <meta name="viewport" content="width=device-width">

  <!-- Use title if it's in the page YAML frontmatter -->
  <title>A Human-Friendly API for Wikipedia
 | Charlie Marsh</title>
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open+Sans">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link href="../static/css/base.css" rel="stylesheet" type="text/css" />
  <link href="../static/css/styles.css" rel="stylesheet" type="text/css" />
  <link href="../static/css/layout.css" rel="stylesheet" type="text/css" />
  <link href="../static/css/skeleton.css" media="screen" rel="stylesheet" type="text/css" />
  <style>
    .darken {
    }
    .darken:hover {
      opacity:.6;
    }
  </style>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-36552582-2', 'princeton.edu');
    ga('send', 'pageview');

  </script>
</head>

<body class="index">
  <div class="container">
    <div id="sidebar" class="four columns">
      <header>
        <h1 style="font-size:50px"><a class="blank" href="/~crmarsh/">Charlie Marsh</a></h1>
        <p><a class="implicit" href="/~crmarsh/">Home</a> &sdot; <a class="implicit" href="../about.html">About Me</a></p>
        <h2>Programmer, student.</h2>
        <p>I'm into functional programming,<br /> machine learning,<br /> and other fun stuff.<p>
          <p>Find me on:</p>
        </header>
        <a class="darken" href="mailto:crmarsh@princeton.edu"><img class="blank" src="../static/img/email.png"></a>
        <a class="darken" href="http://www.github.com/crm416"><img class="blank" src="../static/img/github.png"></a>
        <a class="darken" href="http://stackoverflow.com/users/1450892/charles-marsh"><img class="blank" src="../static/img/stackoverflow.png"></a>
        <a class="darken" href="uk.linkedin.com/in/marshcharles"><img class="blank" src="../static/img/linkedin.png"></a>
      </div>
      <div class="four columns">&nbsp;
      </div>
      <div id="body" class="twelve columns">
        <section class='thing row' style="margin-top:-22px">
          <h1>A Human-Friendly API for Wikipedia</h1>

<p><strong>Motivation:</strong> There's a lot of information on Wikipedia, and people want to use it. Sometimes, these people are programmers; and sometimes, their customers aren't computers.</p>

<p>I needed to parse some information from Wikipedia programatically and present it in a human-readable format, i.e., for clients. I found that a bunch of other people had similar issues (e.g., <a href="http://stackoverflow.com/questions/120061/fetch-a-wikipedia-article-with-python?lq=1">here</a> and <a href="http://stackoverflow.com/questions/4452102/how-to-get-plain-text-out-of-wikipedia?rq=1">here</a>), so I've <a href="https://github.com/crm416/quizzler/blob/master/src/wiki.py">open-sourced my solution</a>.</p>

<blockquote>
  <p>Note that this module is currently housed within a larger project; I'll be writing more on that later.</p>
</blockquote>

<h2>How It Works</h2>

<p>To start, we need to understand the current Wikipedia API, the so-called <em>MediaWiki API</em>. The <a href="http://www.mediawiki.org/wiki/API:Main_page">documentation</a> is fairly comprehensive, although it's not easy to find what you're looking for in those dense pages.</p>

<p>The MediaWiki API returns a JSON (or XML, etc.) response with the information you've queried. But the response is pretty cryptic: to get the <em>actual</em> information you're looking for, you need to access the proper keys and work some other magic.</p>

<p>For example, here's the beginning of the JSON response for <a href="http://en.wikipedia.org/wiki/Michael_Jordan">Michael Jordan's Wikipedia page</a>:</p>

<pre><code class="prettyprint lang-ml">[
    [
        "parse",
        {
            "text": {
                "*": "&lt;div class=\"dablink\"&gt;For other people named Michael Jordan, see &lt;a href=\"/wiki/Michael_Jordan_(disambiguation)\" title=\"Michael Jordan (disambiguation)\"&gt;Michael Jordan (disambiguation)&lt;/a&gt;.&lt;/div&gt;\n&lt;div class=\"metadata topicon nopopups\"..."
            },
            "title": "Michael Jordan"
        }
    ]
]
</code></pre>

<p>Note that the text itself is also still in HTML.</p>

<p>The methods in <em>wikipedia.py</em> are designed to extract the information (i.e., the "<em>" field above) and parse the HTML, with some help from the *HTMLParser</em> library. In the above case, our method looks something like this:</p>

<pre><code class="prettyprint lang-ml">return cleanHTMLSection(cleanWikiSection(json_response[0][1][u'text'][u'*']))
</code></pre>

<p>Where <em>cleanWikiSection</em> is reponsible for removing extraneous information from the page itself, and <em>cleanHTMLSection</em> is responsible for converting the HTML to plaintext.</p>

<h2>BeautifulSoup: Traversing the Parse Tree</h2>

<p>In some cases, <em>wikipedia.py</em> also uses BeautifulSoup to explore the target page. For example, say we want to extract information from the table below (again, from Michael Jordan's Wikipedia page.)</p>

<p><img src="table.png" alt="Michael Jordan" class="center"></p>

<p>We do some fairly low-level searching in the table to check every row and extract information based on the row's content formatting. At this point, <em>wikipedia.py</em> can extract rows with one-to-one (e.g., "Nationality: American") and one-to-many (e.g., "Career highlights and awards: 6x NBA Champion...") formats.</p>

<p>The output for MJ's table is as follows:</p>

<pre><code class="prettyprint lang-ml">[('Born', 'February 17, 1963'), ('Nationality', 'American'), ('Listed height', '6ft6in'), ('Listed weight', '216lb'), ('High school', 'Emsley A. Laney'), ('College', 'North Carolina'), ('NBA Draft', '1984 / Round: 1 / Pick: 3rd overall'), ...]
</code></pre>

<h2>In Conclusion</h2>

<p>Feel free to fork, comment, criticise, or (best of all) get in touch. This was created as a sub-project and is by no means perfect, but I certainly hope it can be useful to some.</p>

<p class="date">Posted on June 16, 2013.</p>

        </section>
      </div>
    </div>

    <script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js?lang=ml"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.0/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="/js/vendor/jquery-1.8.0.min.js"><\/script>')</script>
    <script src="/js/all.js" type="text/javascript"></script>

    <script>
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-3525624-10']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
  </body>
  </html>